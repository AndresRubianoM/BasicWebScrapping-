{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pagina12.com.ar/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p12 = requests.get ( url )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = BeautifulSoup(p12.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = s.find('ul', attrs = {'class': 'hot-sections'}).find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"\"><a href=\"https://www.pagina12.com.ar/secciones/el-pais\">El país</a></li>\n",
      "<a href=\"https://www.pagina12.com.ar/secciones/el-pais\">El país</a>\n",
      "El país\n",
      "https://www.pagina12.com.ar/secciones/el-pais\n"
     ]
    }
   ],
   "source": [
    "section = sections[0]\n",
    "print(section)\n",
    "print(section.a)\n",
    "titulo_section_0 = section.a.text\n",
    "print(section.a.text)\n",
    "url_section_0 = section.a.get('href')\n",
    "print(section.a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_pais = requests.get(url_section_0)\n",
    "s_el_pais = BeautifulSoup(el_pais.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://www.pagina12.com.ar/242882-para-que-se-esta-usando-la-tarjeta-aliment-ar\">Relevamiento de los gastos en Concordia</a>\n",
      "https://www.pagina12.com.ar/242882-para-que-se-esta-usando-la-tarjeta-aliment-ar\n",
      "Relevamiento de los gastos en Concordia\n"
     ]
    }
   ],
   "source": [
    "principal_new = s_el_pais.find('div', attrs = {'class':'featured-article__container'})\n",
    "print(principal_new.a)\n",
    "url_principal_new = principal_new.a.get('href')\n",
    "title_principal_new = principal_new.a.text\n",
    "print(url_principal_new)\n",
    "print(title_principal_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://www.pagina12.com.ar/242883-capacitacion-de-genero-para-todos-los-trabajadores-del-estad\">Capacitación de género para todos los trabajadores del Estado<i>|</i><span>Relanzamiento del INAP y el Ministerio de las Mujeres</span></a>\n",
      "https://www.pagina12.com.ar/242883-capacitacion-de-genero-para-todos-los-trabajadores-del-estad\n",
      "Capacitación de género para todos los trabajadores del Estado|Relanzamiento del INAP y el Ministerio de las Mujeres\n"
     ]
    }
   ],
   "source": [
    "secondary_news =s_el_pais.find('ul', attrs = {'class':'article-list'}).find_all('li')\n",
    "secondary_news_1 = secondary_news[1].a\n",
    "title_secondary_news_1 = secondary_news_1.text\n",
    "url_secondary_news_1 = secondary_news_1.get('href')\n",
    "print(secondary_news_1)\n",
    "print(url_secondary_news_1)\n",
    "print(title_secondary_news_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_news(section):\n",
    "    '''A function that returns a list with the links of all the notes in the section'''\n",
    "    \n",
    "    info_collection = []\n",
    "    \n",
    "    #Adding the title and url of the principal new in the section\n",
    "    section_principal = section.find('div', attrs = {'class':'featured-article__container'})\n",
    "\n",
    "    url  =  section_principal.a.get('href')\n",
    "    \n",
    "    info_collection.append(url)\n",
    "    \n",
    "    #Adding the titles and url's of the new's list \n",
    "    section_list = section.find('ul', attrs = {'class':'article-list'}).find_all('li')\n",
    "    \n",
    "    for article in section_list:\n",
    "    \n",
    "        if article.a:\n",
    "            url   = article.a.get('href')\n",
    "            info_collection.append( url)\n",
    "    \n",
    "    return info_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_el_pais_news = url_news(s_el_pais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pagina12.com.ar/236867-para-recuperar-el-fomeca\n"
     ]
    }
   ],
   "source": [
    "#Download the information \n",
    "url_nota_1 = url_el_pais_news[0]\n",
    "url_nota_1 = 'https://www.pagina12.com.ar/236867-para-recuperar-el-fomeca'\n",
    "print(url_nota_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para recuperar el FOMECA\n",
      "2019-12-17\n",
      "La Ventana\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "Tras cuatro años de la Alianza Cambiemos, el FOMECA sigue vivo. Paralizado primero y subejecutado después, el Fondo de Fomento Concursable para Medios de Comunicación Audiovisual deberá ser una de las políticas públicas que el nuevo gobierno ponga en valor prioritariamente para garantizar la diversidad y el pluralismo en el sistema de medios.\n",
      "\n",
      "\n",
      " La mutilada Ley de Servicios de Comunicación Audiovisual (LSCA) establece en el artículo 97 que se debe destinar específicamente y de forma concursable el 10% de los fondos recaudados en concepto de gravámenes a “los servicios de comunicación audiovisual, comunitarios, de frontera y de pueblos originarios”. Con el FOMECA, los medios comunitarios y de pueblos originarios contaron por primera vez en su historia con una política pública de fomento destinada exclusivamente a promover su desarrollo y sostenibilidad. Esta discriminación positiva les permitió acceder a equipamiento técnico; mejorar la infraestructura física de sus emisoras; fortalecer los procesos de gestión organizacional; y realizar producciones audiovisuales de calidad, que aportan a la diversidad, el pluralismo, la construcción de ciudadanía y la inclusión social.\n",
      "\n",
      "\n",
      " El FOMECA comenzó a implementarse en julio de 2013. Hasta 2019 la recaudación del fondo según la LSCA acumuló más de $1.500 millones. Sin embargo, en seis años solamente se asignó al fondo más de $640 millones de los cuales se pagaron tan solo $340, es decir alrededor de un 23% del fondo previsto por ley. Así, el FOMECA posee un remanente (dinero no ejecutado) que supera los $1000 millones, que debería reasignarse en los futuros concursos, tal como reclaman desde hace años las redes de medios comunitarios, populares y alternativos. https://www.farco.org.ar/trabajadores-y-trabajadoras-de-medios-comunitarios-y-populares-sin-nada-que-festejar/\n",
      "\n",
      "\n",
      "\n",
      " Cambiemos intervino y disolvió la autoridad federal de aplicación para dar lugar a un ente gubernamentalizado que despidió a más de 400 trabajadorxs y jibarizó al área encargada del FOMECA. En paralelo, se encargó a la SIGEN una auditoría “integral” sobre los fondos otorgados entre 2013 y 2015, que duró siete meses y sirvió para congelar los pagos de años anteriores y frenar nuevos concursos por casi un año. A partir de ahí se demonizó a la comunicación comunitaria e indígena y se cuestionó la pertinencia del Estado para apoyar y promover al sector. Además, se hiper burocratizaron los mecanismos y requisitos para presentarse, se cuestionaron las rendiciones con objeciones arbitrarias e infundadas, y se instauraron procesos administrativos interminables que prolongaron aún más los tiempos del FOMECA. En 2019 aún se pagan concursos de 2017 y todavía no se saldaron deudas de 2014 y 2015, las cuales son afectadas por la espiral inflacionaria.\n",
      "\n",
      "\n",
      " Resulta vital que el nuevo gobierno comience a revertir la política comunicacional que durante cuatro años buscó asfixiar y vaciar a los más de 330 medios y proyectos comunitarios e indígenas. Para ello, será imprescindible: pagar las deudas del pasado y reasignar el dinero remanente de años anteriores; llamar a concursos con más frecuencia atendiendo a las demandas prioritarias de los medios; simplificar y agilizar los procesos de presentación y análisis; establecer reglamentos estables y acordes a las necesidades y características del sector no lucrativo; capacitar y acompañar presencialmente; nombrar jurados idóneos y vinculados a la temática; y restituir a los medios comunitarios e indígenas su lugar de participación e incidencia en los organismos de promoción y aplicación. Porque #SinMediosComunitariosNoHayDemocracia.\n",
      "\n",
      "\n",
      "* Profesora de Filosofía (UBA) - @Brendinit1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "** Licenciado en Ciencias de la Comunicación (UBA) - @sajaneiro\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nota = requests.get(url_nota_1)\n",
    "    if nota.status_code == 200:\n",
    "        s_nota = BeautifulSoup(nota.text, 'lxml')\n",
    "        \n",
    "        #get the title\n",
    "        title_nota = s_nota.find('div', attrs = {'class': 'article-title'})\n",
    "        print(title_nota.text)\n",
    "        \n",
    "        #get the date \n",
    "        date_nota = s_nota.find('span', attrs = {'pubdate':'pubdate'}).get('datetime')\n",
    "        print(date_nota)\n",
    "        \n",
    "        #get the article prefix\n",
    "        prefix_nota = s_nota.find('div', attrs = {'class':'article-prefix'})\n",
    "        \n",
    "        if prefix_nota:\n",
    "            print(prefix_nota.text)\n",
    "        else:\n",
    "            print('the news does not have prefix')\n",
    "            \n",
    "        #get the summary\n",
    "        summary_nota = s_nota.find('div', attrs = {'class':'article-summary'})\n",
    "        \n",
    "        if summary_nota:\n",
    "            print(summary_nota.text)\n",
    "        else:\n",
    "            print('the article does not have summary')\n",
    "            \n",
    "        #get the body\n",
    "        body_nota = s_nota.find('div', attrs = {'class':'article-text'}).find_all('p')\n",
    "        if body_nota:\n",
    "            \n",
    "            print('\\n')\n",
    "        \n",
    "            for body in body_nota:\n",
    "                print(body.text)\n",
    "                print('\\n')\n",
    "        else:\n",
    "            print('the body of the new doesnt exist')\n",
    "            \n",
    "        #get the main Image\n",
    "        \n",
    "except Exception as error:\n",
    "    print('Error: ')\n",
    "    print(error)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "media_nota = s_nota.find('div', attrs = {'class':'article-main-media-image'})\n",
    "print(media_nota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ff88092943ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmedia_nota\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "images = media_nota.find_all('img')\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e3ea472bc7cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this article does not have images'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage_src\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data-src'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "if len(images) == 0 :\n",
    "    print('this article does not have images')\n",
    "else:\n",
    "    image = images[-1]\n",
    "    image_src = image.get('data-src')\n",
    "    print(image_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_src' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d2713941ebdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_req\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mimage_src\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_req\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_src' is not defined"
     ]
    }
   ],
   "source": [
    "img_req = requests.get( image_src )\n",
    "Image(img_req.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_image(s_news):\n",
    "    media_news = s_news.find('div', attrs = {'class':'article-main-media-image'})\n",
    "    \n",
    "    if media_news:\n",
    "        main_images = media_news.find_all('img')\n",
    "    \n",
    "        if len(main_images) == 0:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            image_url = main_images[-1].get('data-src')\n",
    "    \n",
    "            #Request of the main image\n",
    "            image_req = requests.get( image_url )\n",
    "            \n",
    "            return image_req.content\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_information (url_news):\n",
    "    news_info = {}\n",
    "    \n",
    "    try:\n",
    "        news_req = requests.get(url_news)\n",
    "        \n",
    "        if news_req.status_code == 200:\n",
    "            s_news = BeautifulSoup(news_req.text, 'lxml')\n",
    "            \n",
    "            #get the title\n",
    "            title_news = s_news.find('div', attrs = {'class': 'article-title'})\n",
    "            if title_news:\n",
    "                news_info['Title'] = title_news.text\n",
    "            else:\n",
    "                print('the news does not have title')\n",
    "                news_info['Title'] = None\n",
    "            \n",
    "            #get the date \n",
    "            date_news = s_news.find('span', attrs = {'pubdate':'pubdate'}).get('datetime')\n",
    "            if date_news:\n",
    "                news_info['Date'] = date_news\n",
    "            else:\n",
    "                print('The article does not have date')\n",
    "                news_info['Date'] = None\n",
    "        \n",
    "            #get the article prefix\n",
    "            prefix_news = s_news.find('div', attrs = {'class':'article-prefix'})\n",
    "            \n",
    "            if prefix_news:\n",
    "                news_info['Prefix'] = prefix_news.text\n",
    "            else:\n",
    "                print('the news does not have prefix')\n",
    "                print('\\n')\n",
    "                news_info['Prefix'] = None\n",
    "            \n",
    "            #get the summary\n",
    "            summary_news = s_news.find('div', attrs = {'class':'article-summary'})\n",
    "            \n",
    "            if summary_news:\n",
    "                news_info['Summary'] = summary_news.text\n",
    "            else:\n",
    "                print('the article does not have summary')\n",
    "                print('\\n')\n",
    "                news_info['Summary'] = None\n",
    "                \n",
    "            #get the body\n",
    "            body_news = s_news.find('div', attrs = {'class':'article-text'}).find_all('p')\n",
    "            body_news_text = []\n",
    "            \n",
    "            if body_news:\n",
    "                for body in body_news:\n",
    "                    body_news_text.append(body.text)\n",
    "                \n",
    "                news_info['Body'] = body_news_text\n",
    "            else:\n",
    "                print('the body of the new doesnt exist')\n",
    "                news_info['Body'] = None\n",
    "            \n",
    "            #get the main Image\n",
    "            main_image = get_main_image(s_news)\n",
    "            \n",
    "            if main_image:\n",
    "                news_info['Image'] = main_image     \n",
    "            else:\n",
    "                print('The article does not have image')\n",
    "                news_info['Image'] = None\n",
    "            \n",
    "            return news_info\n",
    "    \n",
    "    except Exception as error:\n",
    "        print('Error: ')\n",
    "        print(error)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulo_0_info = news_information(url_el_pais_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_sections(url):\n",
    "    \n",
    "    array_url = []\n",
    "    page_request = requests.get(url)\n",
    "    \n",
    "    if page_request.status_code == 200:\n",
    "        s_page = BeautifulSoup(page_request.text, 'lxml')\n",
    "        page_sections = s_page.find('ul', attrs = {'class': 'hot-sections'}).find_all('li')\n",
    "        \n",
    "        for section in page_sections:\n",
    "            array_url.append(section.a.get('href'))\n",
    "        \n",
    "        return array_url\n",
    "    \n",
    "    else:\n",
    "        print('The URL doesnt exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_page_sections = url_sections(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant get the news of the section https://www.pagina12.com.ar/suplementos/cultura-y-espectaculos\n"
     ]
    }
   ],
   "source": [
    "news = []\n",
    "\n",
    "for url_section in url_page_sections:\n",
    "\n",
    "    try:\n",
    "        sect_req = requests.get(url_section)\n",
    "        if sect_req.status_code == 200:\n",
    "            s_sect = BeautifulSoup(sect_req.text, 'lxml')\n",
    "            news.extend(url_news(s_sect))\n",
    "        else:\n",
    "            print('Cant get the news of the section {}'.format(url_section))\n",
    "    \n",
    "    except:\n",
    "        print('Cant get the news of the section {}'.format(url_section))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pagina12.com.ar/236974-cultura-espiritu-y-politica\n"
     ]
    }
   ],
   "source": [
    "print(news[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping news 0/102\n",
      "scrapping news 1/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 2/102\n",
      "scrapping news 3/102\n",
      "scrapping news 4/102\n",
      "scrapping news 5/102\n",
      "scrapping news 6/102\n",
      "scrapping news 7/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 8/102\n",
      "scrapping news 9/102\n",
      "scrapping news 10/102\n",
      "scrapping news 11/102\n",
      "scrapping news 12/102\n",
      "scrapping news 13/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 14/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 15/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 16/102\n",
      "scrapping news 17/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 18/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 19/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 20/102\n",
      "scrapping news 21/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 22/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 23/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "The article does not have image\n",
      "scrapping news 24/102\n",
      "scrapping news 25/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 26/102\n",
      "the news does not have prefix\n",
      "\n",
      "\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "The article does not have image\n",
      "scrapping news 27/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "The article does not have image\n",
      "scrapping news 28/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "The article does not have image\n",
      "scrapping news 29/102\n",
      "scrapping news 30/102\n",
      "scrapping news 31/102\n",
      "scrapping news 32/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 33/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 34/102\n",
      "scrapping news 35/102\n",
      "scrapping news 36/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 37/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 38/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 39/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 40/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 41/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 42/102\n",
      "scrapping news 43/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 44/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 45/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 46/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 47/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 48/102\n",
      "scrapping news 49/102\n",
      "the news does not have prefix\n",
      "\n",
      "\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 50/102\n",
      "scrapping news 51/102\n",
      "scrapping news 52/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 53/102\n",
      "scrapping news 54/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 55/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 56/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 57/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 58/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 59/102\n",
      "scrapping news 60/102\n",
      "scrapping news 61/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 62/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 63/102\n",
      "scrapping news 64/102\n",
      "scrapping news 65/102\n",
      "scrapping news 66/102\n",
      "scrapping news 67/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 68/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 69/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 70/102\n",
      "scrapping news 71/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 72/102\n",
      "scrapping news 73/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 74/102\n",
      "scrapping news 75/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 76/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 77/102\n",
      "scrapping news 78/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 79/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 80/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 81/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 82/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 83/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 84/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 85/102\n",
      "scrapping news 86/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 87/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 88/102\n",
      "scrapping news 89/102\n",
      "scrapping news 90/102\n",
      "scrapping news 91/102\n",
      "scrapping news 92/102\n",
      "scrapping news 93/102\n",
      "scrapping news 94/102\n",
      "scrapping news 95/102\n",
      "scrapping news 96/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 97/102\n",
      "scrapping news 98/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "scrapping news 99/102\n",
      "scrapping news 100/102\n",
      "the article does not have summary\n",
      "\n",
      "\n",
      "The article does not have image\n",
      "scrapping news 101/102\n",
      "scrapping news 102/102\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i, new in enumerate(news):\n",
    "    print('scrapping news {}/{}'.format(i,(len(news) - 1)))\n",
    "    data.append(news_information(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Body</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¿Para qué se está usando la Tarjeta AlimentAr?</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Relevamiento de los gastos en Concordia</td>\n",
       "      <td>El 60 por ciento del dinero fue usado para la ...</td>\n",
       "      <td>[El Ministerio de Desarrollo Social hizo un re...</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Capacitación de género para todos los trabajad...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Relanzamiento del INAP y el Ministerio de las ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[El Instituto Nacional de la Administración Pú...</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nisman: El FBI se ofreció a hacer el peritaje ...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>La iniciativa fue rechazada</td>\n",
       "      <td>Eduardo Rosende, por entonces fiscal de la inv...</td>\n",
       "      <td>[El FBI norteamericano se ofreció en 2016 a ha...</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alberto Fernández inicia su primer viaje rumbo...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>Será el único latinoamericano en el foro en me...</td>\n",
       "      <td>La primera actividad será una cena con todos l...</td>\n",
       "      <td>[Alberto Fernández iniciará este martes su pri...</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El ministro de Interior completó una ronda de ...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>De Pedro, se reunió con Zamora, Perotti, Borde...</td>\n",
       "      <td>Santa Fe, Formosa y Entre Ríos, sellaron conve...</td>\n",
       "      <td>[El ministro de Interior, Eduardo “Wado” De Pe...</td>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date  \\\n",
       "0     ¿Para qué se está usando la Tarjeta AlimentAr?  2020-01-21   \n",
       "1  Capacitación de género para todos los trabajad...  2020-01-21   \n",
       "2  Nisman: El FBI se ofreció a hacer el peritaje ...  2020-01-21   \n",
       "3  Alberto Fernández inicia su primer viaje rumbo...  2020-01-21   \n",
       "4  El ministro de Interior completó una ronda de ...  2020-01-21   \n",
       "\n",
       "                                              Prefix  \\\n",
       "0            Relevamiento de los gastos en Concordia   \n",
       "1  Relanzamiento del INAP y el Ministerio de las ...   \n",
       "2                       La iniciativa fue rechazada    \n",
       "3  Será el único latinoamericano en el foro en me...   \n",
       "4  De Pedro, se reunió con Zamora, Perotti, Borde...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  El 60 por ciento del dinero fue usado para la ...   \n",
       "1                                               None   \n",
       "2  Eduardo Rosende, por entonces fiscal de la inv...   \n",
       "3  La primera actividad será una cena con todos l...   \n",
       "4  Santa Fe, Formosa y Entre Ríos, sellaron conve...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  [El Ministerio de Desarrollo Social hizo un re...   \n",
       "1  [El Instituto Nacional de la Administración Pú...   \n",
       "2  [El FBI norteamericano se ofreció en 2016 a ha...   \n",
       "3  [Alberto Fernández iniciará este martes su pri...   \n",
       "4  [El ministro de Interior, Eduardo “Wado” De Pe...   \n",
       "\n",
       "                                               Image  \n",
       "0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "1  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "2  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "3  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  \n",
       "4  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Notes_Pagina12.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
